
########## Setting Up Experiment ######################

Putting log in GRU_SGD_LR_SCHEDULE_model=GRU_optimizer=SGD_LR_SCHEDULE_initial_lr=10_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_save_best_0
Using the GPU
Loading data from data
  vocabulary size: 10000

########## Running Main Loop ##########################

EPOCH 0 ------------------
step: 10	loss: 3543.6354446411133	speed (wps):1364.0264181403572
step: 142	loss: 36693.387422561646	speed (wps):1417.1134605962827
step: 274	loss: 67493.475959301	speed (wps):1416.548289899621
step: 406	loss: 97045.43864965439	speed (wps):1416.6096424512705
step: 538	loss: 126093.56308937073	speed (wps):1416.2817666232522
step: 670	loss: 154776.2144780159	speed (wps):1415.9966479211269
step: 802	loss: 182728.27835083008	speed (wps):1415.8497101117337
step: 934	loss: 210514.17078018188	speed (wps):1415.4780628310882
step: 1066	loss: 238126.40110731125	speed (wps):1415.4131545367225
step: 1198	loss: 265356.50992155075	speed (wps):1415.1714837221657
Saving model parameters to best_params.pt
epoch: 0	train ppl: 532.4330376508981	val ppl: 301.5911712944497	best val: 301.5911712944497	time (s) spent in epoch: 682.0826041698456

EPOCH 1 ------------------
step: 10	loss: 2318.5173511505127	speed (wps):1371.7894613082387
step: 142	loss: 28982.144725322723	speed (wps):1411.653555324465
step: 274	loss: 56011.92347049713	speed (wps):1413.0836660718987
step: 406	loss: 82605.59664011002	speed (wps):1413.4063227512643
step: 538	loss: 109218.28418016434	speed (wps):1413.4546337067727
step: 670	loss: 135765.79130649567	speed (wps):1413.5945776926962
step: 802	loss: 161825.0946354866	speed (wps):1413.620214147052
step: 934	loss: 187935.8780145645	speed (wps):1413.804481672583
step: 1066	loss: 213956.2618780136	speed (wps):1413.6345091877333
step: 1198	loss: 239644.68532323837	speed (wps):1413.763673681049
Saving model parameters to best_params.pt
epoch: 1	train ppl: 297.7953472290546	val ppl: 230.9154337878334	best val: 230.9154337878334	time (s) spent in epoch: 681.8083388805389

EPOCH 2 ------------------
step: 10	loss: 2206.710937023163	speed (wps):1377.8747287971576
step: 142	loss: 27616.78413629532	speed (wps):1413.633969623534
step: 274	loss: 53581.307826042175	speed (wps):1413.6064741087425
step: 406	loss: 79077.92387723923	speed (wps):1413.930375702989
step: 538	loss: 104690.15719413757	speed (wps):1413.8435020678608
step: 670	loss: 130224.85552549362	speed (wps):1413.668942454334
step: 802	loss: 155354.01108026505	speed (wps):1413.4295887247947
step: 934	loss: 180570.87338209152	speed (wps):1413.3938444246908
step: 1066	loss: 205752.56118059158	speed (wps):1413.1828768743035
step: 1198	loss: 230578.55288743973	speed (wps):1413.4149202823728
Saving model parameters to best_params.pt
epoch: 2	train ppl: 240.99370909736442	val ppl: 209.4447285109516	best val: 209.4447285109516	time (s) spent in epoch: 683.3514351844788

EPOCH 3 ------------------
step: 10	loss: 2146.632375717163	speed (wps):1363.285500355172
step: 142	loss: 26754.23338651657	speed (wps):1412.4019382327133
step: 274	loss: 52013.31656455994	speed (wps):1413.231252529461
step: 406	loss: 76751.53571844101	speed (wps):1413.3806779590009
step: 538	loss: 101661.86438560486	speed (wps):1413.082960223737
step: 670	loss: 126490.55645465851	speed (wps):1413.0798503830472
step: 802	loss: 150886.29335403442	speed (wps):1412.8824126186316
step: 934	loss: 175535.1263666153	speed (wps):1412.9437188227698
step: 1066	loss: 200103.30054044724	speed (wps):1412.71282212792
step: 1198	loss: 224275.90876817703	speed (wps):1412.7560239916315
Saving model parameters to best_params.pt
epoch: 3	train ppl: 207.8485737364653	val ppl: 181.19535118076428	best val: 181.19535118076428	time (s) spent in epoch: 682.7711322307587

EPOCH 4 ------------------
step: 10	loss: 2098.231484889984	speed (wps):1368.5301225955432
step: 142	loss: 26081.0374045372	speed (wps):1410.1678669410676
step: 274	loss: 50832.74800539017	speed (wps):1411.1559282733297
step: 406	loss: 74963.99842739105	speed (wps):1411.5267928913613
step: 538	loss: 99288.62168312073	speed (wps):1411.3966196626461
step: 670	loss: 123598.41302394867	speed (wps):1411.916506997822
step: 802	loss: 147452.97880887985	speed (wps):1412.1610974636774
step: 934	loss: 171570.75036764145	speed (wps):1412.5455209688719
step: 1066	loss: 195653.45319986343	speed (wps):1412.6827245179118
step: 1198	loss: 219275.88997364044	speed (wps):1412.7959803672966
Saving model parameters to best_params.pt
epoch: 4	train ppl: 184.80613516445308	val ppl: 168.24225497984497	best val: 168.24225497984497	time (s) spent in epoch: 681.3921003341675

EPOCH 5 ------------------
step: 10	loss: 2045.240352153778	speed (wps):1365.1361323827975
step: 142	loss: 25504.722878932953	speed (wps):1408.792813523662
step: 274	loss: 49777.07708120346	speed (wps):1410.4599297793513
step: 406	loss: 73409.98143434525	speed (wps):1411.1278146079055
step: 538	loss: 97287.18688964844	speed (wps):1411.125706949827
step: 670	loss: 121140.00508785248	speed (wps):1411.1764029723904
step: 802	loss: 144521.6403722763	speed (wps):1411.172236886401
step: 934	loss: 168218.8963484764	speed (wps):1411.097571431458
step: 1066	loss: 191889.85310792923	speed (wps):1411.1220748136625
step: 1198	loss: 215057.94804096222	speed (wps):1411.1351218434359
Saving model parameters to best_params.pt
epoch: 5	train ppl: 167.29892588120762	val ppl: 152.6312882342029	best val: 152.6312882342029	time (s) spent in epoch: 679.5944414138794

EPOCH 6 ------------------
step: 10	loss: 2007.945055961609	speed (wps):1361.8638460881289
step: 142	loss: 25023.69591474533	speed (wps):1409.0687256809902
step: 274	loss: 48935.61755180359	speed (wps):1410.381112609244
step: 406	loss: 72123.74912500381	speed (wps):1411.2837489459473
step: 538	loss: 95580.42881727219	speed (wps):1411.5878045926156
step: 670	loss: 119015.30258655548	speed (wps):1411.6813098064124
step: 802	loss: 142006.9069647789	speed (wps):1411.705786199141
step: 934	loss: 165343.9709186554	speed (wps):1411.646776859963
step: 1066	loss: 188640.77071666718	speed (wps):1411.8245769615444
step: 1198	loss: 211389.68789815903	speed (wps):1411.7407257077268
Saving model parameters to best_params.pt
epoch: 6	train ppl: 153.37304788848004	val ppl: 148.58446203278254	best val: 148.58446203278254	time (s) spent in epoch: 676.6420645713806

EPOCH 7 ------------------
step: 10	loss: 1974.7800946235657	speed (wps):1363.9927173512876
step: 142	loss: 24595.663487911224	speed (wps):1407.9785914999695
step: 274	loss: 48168.627433776855	speed (wps):1410.4013888951847
step: 406	loss: 71001.08038902283	speed (wps):1411.278033606178
step: 538	loss: 94094.65575933456	speed (wps):1411.5936394051876
step: 670	loss: 117171.50255918503	speed (wps):1411.6965127479834
step: 802	loss: 139795.8824110031	speed (wps):1412.0994467613832
step: 934	loss: 162782.80128479004	speed (wps):1412.1745608383947
step: 1066	loss: 185759.7779250145	speed (wps):1412.3479175360198
step: 1198	loss: 208139.97690439224	speed (wps):1412.282659243545
Saving model parameters to best_params.pt
epoch: 7	train ppl: 142.10580506096255	val ppl: 138.7846704481932	best val: 138.7846704481932	time (s) spent in epoch: 684.3755216598511

EPOCH 8 ------------------
step: 10	loss: 1956.1607098579407	speed (wps):1369.9065802948348
step: 142	loss: 24249.312019348145	speed (wps):1411.0154940620741
step: 274	loss: 47498.45311641693	speed (wps):1411.6849620432456
step: 406	loss: 69994.45915222168	speed (wps):1412.2082912254664
step: 538	loss: 92775.48606395721	speed (wps):1412.3048062843282
step: 670	loss: 115549.26459550858	speed (wps):1412.4553347422766
step: 802	loss: 137878.93771886826	speed (wps):1412.309071301
step: 934	loss: 160577.22730636597	speed (wps):1412.4245614059244
step: 1066	loss: 183289.11248207092	speed (wps):1412.381700498491
step: 1198	loss: 205373.62029790878	speed (wps):1412.4090391436473
Saving model parameters to best_params.pt
epoch: 8	train ppl: 133.01521488281662	val ppl: 132.4769038845778	best val: 132.4769038845778	time (s) spent in epoch: 682.3501229286194

EPOCH 9 ------------------
step: 10	loss: 1922.4465370178223	speed (wps):1372.8369145633362
step: 142	loss: 23908.37045431137	speed (wps):1410.5539696359363
step: 274	loss: 46856.954255104065	speed (wps):1411.3782948158384
step: 406	loss: 69072.71265506744	speed (wps):1411.8536751840586
step: 538	loss: 91569.61610794067	speed (wps):1411.9004757111836
step: 670	loss: 114032.06396579742	speed (wps):1412.1543890892815
step: 802	loss: 136068.02247285843	speed (wps):1412.1187722381565
step: 934	loss: 158512.33446836472	speed (wps):1412.2198428000022
step: 1066	loss: 180952.83442735672	speed (wps):1412.1620653296848
step: 1198	loss: 202776.28089427948	speed (wps):1412.2761576948376
Saving model parameters to best_params.pt
epoch: 9	train ppl: 125.06272885137658	val ppl: 129.14050725608692	best val: 129.14050725608692	time (s) spent in epoch: 683.2310082912445

EPOCH 10 ------------------
step: 10	loss: 1909.160635471344	speed (wps):1365.6841305117437
step: 142	loss: 23615.099890232086	speed (wps):1410.6573060582043
step: 274	loss: 46310.15270471573	speed (wps):1411.591439748213
step: 406	loss: 68271.50746822357	speed (wps):1412.263529188475
step: 538	loss: 90518.05834531784	speed (wps):1412.4304811190977
step: 670	loss: 112744.7817158699	speed (wps):1412.8221338442263
step: 802	loss: 134507.85946130753	speed (wps):1412.6638908471837
step: 934	loss: 156679.72366571426	speed (wps):1412.7359931979165
step: 1066	loss: 178845.86349010468	speed (wps):1412.6730230978678
step: 1198	loss: 200371.79770708084	speed (wps):1412.5650847956222
Saving model parameters to best_params.pt
epoch: 10	train ppl: 118.15823475864141	val ppl: 128.3511987720561	best val: 128.3511987720561	time (s) spent in epoch: 684.9367752075195

EPOCH 11 ------------------
step: 10	loss: 1881.9188070297241	speed (wps):1375.0284745799659
step: 142	loss: 23346.864128112793	speed (wps):1412.0660790823647
step: 274	loss: 45822.605130672455	speed (wps):1412.2204715125781
step: 406	loss: 67541.17648363113	speed (wps):1412.573518410733
step: 538	loss: 89499.95351791382	speed (wps):1412.5077934524957
step: 670	loss: 111447.56390810013	speed (wps):1412.6029957907983
step: 802	loss: 132977.02896356583	speed (wps):1412.5823827194745
step: 934	loss: 154901.8929219246	speed (wps):1412.7436386891113
step: 1066	loss: 176894.15281534195	speed (wps):1412.9305798568687
step: 1198	loss: 198145.24924993515	speed (wps):1413.0607915609503
Saving model parameters to best_params.pt
epoch: 11	train ppl: 112.02659428699137	val ppl: 124.41157010265708	best val: 124.41157010265708	time (s) spent in epoch: 686.8198184967041

EPOCH 12 ------------------
step: 10	loss: 1851.4248847961426	speed (wps):1370.0194341177555
step: 142	loss: 23094.012229442596	speed (wps):1411.9771235735907
step: 274	loss: 45330.96001625061	speed (wps):1412.154028974539
step: 406	loss: 66772.6201248169	speed (wps):1412.7570104216563
step: 538	loss: 88518.40613603592	speed (wps):1412.5470939288148
step: 670	loss: 110235.46640634537	speed (wps):1412.8040464571136
step: 802	loss: 131529.7747027874	speed (wps):1412.692233289717
step: 934	loss: 153249.62257027626	speed (wps):1412.7380456072162
step: 1066	loss: 174979.0807044506	speed (wps):1412.6844158619226
step: 1198	loss: 196035.06268501282	speed (wps):1412.716602227375
Saving model parameters to best_params.pt
epoch: 12	train ppl: 106.53294162785528	val ppl: 120.30802833514623	best val: 120.30802833514623	time (s) spent in epoch: 697.0536937713623

EPOCH 13 ------------------
step: 10	loss: 1843.553626537323	speed (wps):1370.7527974656632
step: 142	loss: 22816.2029004097	speed (wps):1411.2687669998122
step: 274	loss: 44832.76934146881	speed (wps):1413.6286054572583
step: 406	loss: 66089.96211051941	speed (wps):1413.2888842517686
step: 538	loss: 87616.54929637909	speed (wps):1413.4925993721663
step: 670	loss: 109104.76649522781	speed (wps):1413.5433388062575
step: 802	loss: 130176.53955817223	speed (wps):1413.4232741258415
step: 934	loss: 151681.29954218864	speed (wps):1413.231010986203
step: 1066	loss: 173191.0419666767	speed (wps):1413.2198689218744
step: 1198	loss: 194040.71373462677	speed (wps):1412.9743346254365
epoch: 13	train ppl: 101.66303118982401	val ppl: 121.7054897010312	best val: 120.30802833514623	time (s) spent in epoch: 671.0116543769836

EPOCH 14 ------------------
step: 10	loss: 1831.3178992271423	speed (wps):1393.490207878786
step: 142	loss: 22626.59822702408	speed (wps):1410.0974924033212
step: 274	loss: 44425.805888175964	speed (wps):1411.1573933024815
step: 406	loss: 65458.25658082962	speed (wps):1411.3042972165508
step: 538	loss: 86775.27383327484	speed (wps):1411.5674674874545
step: 670	loss: 108119.8692202568	speed (wps):1411.8098385425003
step: 802	loss: 128972.91639089584	speed (wps):1411.7475946726954
step: 934	loss: 150311.4244055748	speed (wps):1411.9230641993552
step: 1066	loss: 171622.16370224953	speed (wps):1411.945402235227
step: 1198	loss: 192270.0083041191	speed (wps):1412.2239588024827
Saving model parameters to best_params.pt
epoch: 14	train ppl: 97.47833692493161	val ppl: 117.02675028361546	best val: 117.02675028361546	time (s) spent in epoch: 679.1389455795288

EPOCH 15 ------------------
step: 10	loss: 1813.3654356002808	speed (wps):1363.2543681166687
step: 142	loss: 22331.570646762848	speed (wps):1409.7944823707537
step: 274	loss: 43813.29559087753	speed (wps):1410.9245559753367
step: 406	loss: 64515.56128978729	speed (wps):1411.4577030958858
step: 538	loss: 85475.67604780197	speed (wps):1411.5969005752224
step: 670	loss: 106420.55168867111	speed (wps):1411.5634836985212
step: 802	loss: 126916.50968670845	speed (wps):1411.7300224364533
step: 934	loss: 147856.0508930683	speed (wps):1411.7514542493416
step: 1066	loss: 168800.71270227432	speed (wps):1411.8324240808745
step: 1198	loss: 189041.67692184448	speed (wps):1411.8103533362907
Saving model parameters to best_params.pt
epoch: 15	train ppl: 90.16191908649222	val ppl: 114.52539863157087	best val: 114.52539863157087	time (s) spent in epoch: 681.6055500507355

EPOCH 16 ------------------
step: 10	loss: 1787.4084663391113	speed (wps):1364.6967471629719
step: 142	loss: 21933.47460269928	speed (wps):1412.605955288697
step: 274	loss: 43068.77794981003	speed (wps):1414.1572585582874
step: 406	loss: 63366.43028259277	speed (wps):1414.1994802281679
step: 538	loss: 83890.76821088791	speed (wps):1414.6924006152112
step: 670	loss: 104398.91688346863	speed (wps):1414.953481514178
step: 802	loss: 124454.76598501205	speed (wps):1414.5436819069198
step: 934	loss: 144937.64651417732	speed (wps):1414.6754752287532
step: 1066	loss: 165395.01454353333	speed (wps):1414.4627542231822
step: 1198	loss: 185140.09631037712	speed (wps):1414.2763670395495
Saving model parameters to best_params.pt
epoch: 16	train ppl: 82.03683381863573	val ppl: 111.79205920941833	best val: 111.79205920941833	time (s) spent in epoch: 687.300537109375

EPOCH 17 ------------------
step: 10	loss: 1748.8211846351624	speed (wps):1361.409118054303
step: 142	loss: 21537.247401475906	speed (wps):1411.0309154998795
step: 274	loss: 42284.63285803795	speed (wps):1411.8478220457268
step: 406	loss: 62154.04832839966	speed (wps):1412.2971120297987
step: 538	loss: 82241.17726802826	speed (wps):1412.1975892387054
step: 670	loss: 102293.20930957794	speed (wps):1412.3436194815713
step: 802	loss: 121896.7671763897	speed (wps):1412.323375283118
step: 934	loss: 141931.63070082664	speed (wps):1412.4359301442312
step: 1066	loss: 161936.20391249657	speed (wps):1412.3822474831322
step: 1198	loss: 181166.03621959686	speed (wps):1412.390376661531
Saving model parameters to best_params.pt
epoch: 17	train ppl: 74.49381815117837	val ppl: 109.48932613988494	best val: 109.48932613988494	time (s) spent in epoch: 693.0317184925079

EPOCH 18 ------------------
step: 10	loss: 1732.19797372818	speed (wps):1379.9236764021305
step: 142	loss: 21236.933134794235	speed (wps):1415.5192863678803
step: 274	loss: 41659.442430734634	speed (wps):1415.9712211505123
step: 406	loss: 61230.861678123474	speed (wps):1415.0793886188135
step: 538	loss: 81021.71028852463	speed (wps):1414.7846276527785
step: 670	loss: 100741.87927722931	speed (wps):1414.7890487841103
step: 802	loss: 120007.93175578117	speed (wps):1414.7013091304154
step: 934	loss: 139697.01976776123	speed (wps):1414.42462917024
step: 1066	loss: 159346.75112128258	speed (wps):1414.1902514827873
step: 1198	loss: 178211.46845459938	speed (wps):1413.9873421326117
Saving model parameters to best_params.pt
epoch: 18	train ppl: 69.32663798880371	val ppl: 107.25531712458283	best val: 107.25531712458283	time (s) spent in epoch: 691.6746988296509

EPOCH 19 ------------------
step: 10	loss: 1704.352593421936	speed (wps):1373.1358219114888
step: 142	loss: 20980.545924901962	speed (wps):1412.6592502670965
step: 274	loss: 41244.02009725571	speed (wps):1412.6876179726366
step: 406	loss: 60649.78874087334	speed (wps):1412.5111082905585
step: 538	loss: 80274.64969873428	speed (wps):1412.1820043469706
step: 670	loss: 99808.55043888092	speed (wps):1412.1568103737463
step: 802	loss: 118913.049929142	speed (wps):1412.188754021536
step: 934	loss: 138422.07137823105	speed (wps):1412.0055377579222
step: 1066	loss: 157850.3250825405	speed (wps):1412.1516014563017
step: 1198	loss: 176538.09937238693	speed (wps):1412.1283396793992
Saving model parameters to best_params.pt
epoch: 19	train ppl: 66.58190543697219	val ppl: 105.65461818098676	best val: 105.65461818098676	time (s) spent in epoch: 702.5269546508789

EPOCH 20 ------------------
step: 10	loss: 1703.8793015480042	speed (wps):1369.3406159300819
step: 142	loss: 20929.906539916992	speed (wps):1411.2643647761906
step: 274	loss: 41118.53442311287	speed (wps):1412.478676174075
step: 406	loss: 60441.45152926445	speed (wps):1412.1766535154907
step: 538	loss: 79980.68989992142	speed (wps):1412.1173723673664
step: 670	loss: 99485.70393919945	speed (wps):1412.1073305642644
step: 802	loss: 118510.56247115135	speed (wps):1411.9172293561262
step: 934	loss: 137946.22737646103	speed (wps):1411.9943938271192
step: 1066	loss: 157334.6398985386	speed (wps):1412.0976848569728
step: 1198	loss: 175927.76584386826	speed (wps):1412.0645922944002
Saving model parameters to best_params.pt
epoch: 20	train ppl: 65.6562260965593	val ppl: 103.56494160593782	best val: 103.56494160593782	time (s) spent in epoch: 682.1705808639526

EPOCH 21 ------------------
step: 10	loss: 1693.1853485107422	speed (wps):1368.2110743612868
step: 142	loss: 20906.45884037018	speed (wps):1410.0910042236583
step: 274	loss: 41118.895963430405	speed (wps):1411.3688530812735
step: 406	loss: 60425.36722421646	speed (wps):1411.9492265010813
step: 538	loss: 79980.45754313469	speed (wps):1412.0929879020096
step: 670	loss: 99470.1571381092	speed (wps):1411.9301738505876
step: 802	loss: 118472.77939677238	speed (wps):1412.0809887141932
step: 934	loss: 137887.1830511093	speed (wps):1411.9238572033807
step: 1066	loss: 157243.0993437767	speed (wps):1411.923490894464
step: 1198	loss: 175837.2457230091	speed (wps):1411.9727189771888
Saving model parameters to best_params.pt
epoch: 21	train ppl: 65.516043599387	val ppl: 102.86699736014931	best val: 102.86699736014931	time (s) spent in epoch: 702.021812915802

EPOCH 22 ------------------
step: 10	loss: 1696.2633228302002	speed (wps):1366.7341341292881
step: 142	loss: 20908.512291908264	speed (wps):1412.0771779375466
step: 274	loss: 41127.49359846115	speed (wps):1413.0669554005724
step: 406	loss: 60396.99533820152	speed (wps):1412.7074807680742
step: 538	loss: 79974.84264492989	speed (wps):1412.7702886246966
step: 670	loss: 99462.96769618988	speed (wps):1412.7917790709464
step: 802	loss: 118497.04766750336	speed (wps):1413.1160707794718
step: 934	loss: 137941.20854496956	speed (wps):1413.0655208811286
step: 1066	loss: 157304.37038898468	speed (wps):1413.3887636943987
step: 1198	loss: 175873.1592953205	speed (wps):1413.3575221733752
Saving model parameters to best_params.pt
epoch: 22	train ppl: 65.4666536223773	val ppl: 102.82463739895215	best val: 102.82463739895215	time (s) spent in epoch: 690.4943997859955

EPOCH 23 ------------------
step: 10	loss: 1702.0058941841125	speed (wps):1367.1469947534226
step: 142	loss: 20896.991600990295	speed (wps):1411.2037848094092
step: 274	loss: 41126.48876070976	speed (wps):1411.7414545943527
step: 406	loss: 60411.55267238617	speed (wps):1412.2472791384625
step: 538	loss: 79993.20493102074	speed (wps):1412.1917418710107
step: 670	loss: 99509.69127893448	speed (wps):1412.2548925337614
step: 802	loss: 118546.17820620537	speed (wps):1412.3210249667607
step: 934	loss: 137960.34211874008	speed (wps):1412.1822990526375
step: 1066	loss: 157326.69303774834	speed (wps):1412.2699653228824
step: 1198	loss: 175898.3539891243	speed (wps):1412.2352381229987
Saving model parameters to best_params.pt
epoch: 23	train ppl: 65.54590902082123	val ppl: 102.78262115117973	best val: 102.78262115117973	time (s) spent in epoch: 679.271525144577

EPOCH 24 ------------------
step: 10	loss: 1700.8733582496643	speed (wps):1377.5395577040726
step: 142	loss: 20914.44761633873	speed (wps):1410.969046841849
step: 274	loss: 41144.78125214577	speed (wps):1412.8803381298744
step: 406	loss: 60429.0380859375	speed (wps):1412.8191666577304
step: 538	loss: 80028.99177312851	speed (wps):1412.8841193094631
step: 670	loss: 99492.96756505966	speed (wps):1412.589456697947
step: 802	loss: 118524.26470398903	speed (wps):1412.5224199573784
step: 934	loss: 137976.92815423012	speed (wps):1412.5726629327844
step: 1066	loss: 157295.20176291466	speed (wps):1412.4795990303771
step: 1198	loss: 175857.0741724968	speed (wps):1412.5498325891315
Saving model parameters to best_params.pt
epoch: 24	train ppl: 65.43633867411458	val ppl: 102.77631111691726	best val: 102.77631111691726	time (s) spent in epoch: 679.0309658050537

EPOCH 25 ------------------
step: 10	loss: 1702.3581385612488	speed (wps):1363.2406151406508
step: 142	loss: 20905.55163502693	speed (wps):1409.522767190986
step: 274	loss: 41122.324838638306	speed (wps):1410.5520503491862
step: 406	loss: 60408.50955367088	speed (wps):1411.2438158734924
step: 538	loss: 79967.8114426136	speed (wps):1411.378466962777
step: 670	loss: 99444.32035684586	speed (wps):1411.5606770858026
step: 802	loss: 118472.15099453926	speed (wps):1411.8707512390445
step: 934	loss: 137913.81022930145	speed (wps):1412.0409425482912
step: 1066	loss: 157255.58041214943	speed (wps):1412.301348026967
step: 1198	loss: 175832.46231079102	speed (wps):1412.256710630994
Saving model parameters to best_params.pt
epoch: 25	train ppl: 65.44452349946911	val ppl: 102.77198454018377	best val: 102.77198454018377	time (s) spent in epoch: 682.1156551837921

EPOCH 26 ------------------
step: 10	loss: 1705.6569290161133	speed (wps):1363.1184042298694
step: 142	loss: 20930.044184923172	speed (wps):1410.2461070062395
step: 274	loss: 41136.450312137604	speed (wps):1411.2653057491818
step: 406	loss: 60417.801204919815	speed (wps):1411.6324205353053
step: 538	loss: 79968.24199318886	speed (wps):1411.7780539033079
step: 670	loss: 99475.96975445747	speed (wps):1411.7613218804288
step: 802	loss: 118511.92220687866	speed (wps):1412.0380855989285
step: 934	loss: 137935.14766693115	speed (wps):1411.947162624217
step: 1066	loss: 157285.64668774605	speed (wps):1412.040541689906
step: 1198	loss: 175861.07209444046	speed (wps):1412.0460844775262
Saving model parameters to best_params.pt
epoch: 26	train ppl: 65.47598064541526	val ppl: 102.77094889581309	best val: 102.77094889581309	time (s) spent in epoch: 692.5516548156738

EPOCH 27 ------------------
step: 10	loss: 1699.2375898361206	speed (wps):1368.7634008095656
step: 142	loss: 20923.27160835266	speed (wps):1411.5784146768065
step: 274	loss: 41156.36229157448	speed (wps):1413.2035557677737
step: 406	loss: 60420.06814599037	speed (wps):1413.3651193459798
step: 538	loss: 80004.53775048256	speed (wps):1413.1053877140464
step: 670	loss: 99504.97325539589	speed (wps):1412.8865417528107
step: 802	loss: 118536.30257964134	speed (wps):1412.9471462923957
step: 934	loss: 137950.80393314362	speed (wps):1412.7347725152279
step: 1066	loss: 157301.57693386078	speed (wps):1412.6706699072554
step: 1198	loss: 175870.1544702053	speed (wps):1412.5899739932527
Saving model parameters to best_params.pt
epoch: 27	train ppl: 65.43467312491809	val ppl: 102.77086768754751	best val: 102.77086768754751	time (s) spent in epoch: 683.8868160247803

EPOCH 28 ------------------
step: 10	loss: 1702.3895144462585	speed (wps):1370.3980544302285
step: 142	loss: 20910.270467996597	speed (wps):1410.1315729026696
step: 274	loss: 41140.14974594116	speed (wps):1411.4939644665828
step: 406	loss: 60389.83080506325	speed (wps):1411.5795747228356
step: 538	loss: 79999.31919813156	speed (wps):1411.8980785374508
step: 670	loss: 99495.91021418571	speed (wps):1412.264009119732
step: 802	loss: 118510.42601943016	speed (wps):1412.9146309550972
step: 934	loss: 137922.05800652504	speed (wps):1413.246117784289
step: 1066	loss: 157281.45045518875	speed (wps):1413.1913816990134
step: 1198	loss: 175837.85417318344	speed (wps):1413.3303594725667
epoch: 28	train ppl: 65.41038739252525	val ppl: 102.77088775625084	best val: 102.77086768754751	time (s) spent in epoch: 670.9173774719238

EPOCH 29 ------------------
step: 10	loss: 1705.1534295082092	speed (wps):1395.1234393323307
step: 142	loss: 20891.657366752625	speed (wps):1411.9329301690648
step: 274	loss: 41111.35543704033	speed (wps):1411.527975641364
step: 406	loss: 60368.10045957565	speed (wps):1411.9473129122166
step: 538	loss: 79941.24718308449	speed (wps):1411.885432730461
step: 670	loss: 99457.56703019142	speed (wps):1411.9250727827095
step: 802	loss: 118456.99456453323	speed (wps):1411.8997856465166
step: 934	loss: 137938.49762678146	speed (wps):1411.8136570647084
step: 1066	loss: 157299.50226187706	speed (wps):1411.8795283545614
step: 1198	loss: 175877.99444437027	speed (wps):1411.9249822861996
epoch: 29	train ppl: 65.48169376027487	val ppl: 102.77088588939458	best val: 102.77086768754751	time (s) spent in epoch: 671.5387041568756

EPOCH 30 ------------------
step: 10	loss: 1709.793004989624	speed (wps):1392.340239289544
step: 142	loss: 20894.066191911697	speed (wps):1411.3177103811588
step: 274	loss: 41133.543227910995	speed (wps):1412.1492374495574
step: 406	loss: 60411.782809495926	speed (wps):1412.5550921828044
step: 538	loss: 79984.24313545227	speed (wps):1412.525217473897
step: 670	loss: 99483.06231498718	speed (wps):1412.6185619661576
step: 802	loss: 118488.43381881714	speed (wps):1412.4381298139187
step: 934	loss: 137959.36077952385	speed (wps):1412.5845108847834
step: 1066	loss: 157319.77442145348	speed (wps):1412.438644573804
step: 1198	loss: 175885.08132219315	speed (wps):1412.426776127261
epoch: 30	train ppl: 65.48847503633432	val ppl: 102.7708882229649	best val: 102.77086768754751	time (s) spent in epoch: 671.2577967643738

EPOCH 31 ------------------
step: 10	loss: 1703.2120299339294	speed (wps):1394.8228354686319
step: 142	loss: 20950.003086328506	speed (wps):1411.6677328962448
step: 274	loss: 41196.747019290924	speed (wps):1411.760217331792
step: 406	loss: 60482.692301273346	speed (wps):1412.009386240167
step: 538	loss: 80061.46459579468	speed (wps):1412.069949942523
step: 670	loss: 99554.7203552723	speed (wps):1411.8157997812423
step: 802	loss: 118565.73195815086	speed (wps):1412.135987066238
step: 934	loss: 137998.33824038506	speed (wps):1412.2057830034598
step: 1066	loss: 157357.18102693558	speed (wps):1412.4668422607629
step: 1198	loss: 175931.04360580444	speed (wps):1412.4326868540084
epoch: 31	train ppl: 65.55653940981722	val ppl: 102.77088775625084	best val: 102.77086768754751	time (s) spent in epoch: 671.1671180725098

EPOCH 32 ------------------
step: 10	loss: 1701.7214751243591	speed (wps):1393.8099674241066
step: 142	loss: 20889.28359746933	speed (wps):1409.9424696560932
step: 274	loss: 41092.151259183884	speed (wps):1411.259212881174
step: 406	loss: 60367.114864587784	speed (wps):1411.1211173612237
step: 538	loss: 79965.53124189377	speed (wps):1411.2567422716656
step: 670	loss: 99484.84152793884	speed (wps):1411.2794928688566
step: 802	loss: 118507.17639565468	speed (wps):1411.2539092802488
step: 934	loss: 137961.33888721466	speed (wps):1411.4257995751732
step: 1066	loss: 157339.3574464321	speed (wps):1411.5502466773682
step: 1198	loss: 175918.31047058105	speed (wps):1411.522335934901
epoch: 32	train ppl: 65.52125567054026	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 671.623517036438

EPOCH 33 ------------------
step: 10	loss: 1699.4487762451172	speed (wps):1396.399116764979
step: 142	loss: 20884.526596069336	speed (wps):1410.6264514133268
step: 274	loss: 41099.16600584984	speed (wps):1412.572036814028
step: 406	loss: 60376.44742965698	speed (wps):1413.0823807193017
step: 538	loss: 79966.39205098152	speed (wps):1413.6099482903255
step: 670	loss: 99452.01248884201	speed (wps):1413.328693749748
step: 802	loss: 118466.09213590622	speed (wps):1412.985230235516
step: 934	loss: 137894.02246832848	speed (wps):1412.7183462137652
step: 1066	loss: 157266.54589176178	speed (wps):1412.5504987965476
step: 1198	loss: 175832.00162768364	speed (wps):1412.333683323038
epoch: 33	train ppl: 65.37418685542725	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 671.4652671813965

EPOCH 34 ------------------
step: 10	loss: 1700.199043750763	speed (wps):1394.4442072118823
step: 142	loss: 20880.50345659256	speed (wps):1409.3581911791853
step: 274	loss: 41078.29961538315	speed (wps):1409.8605886720627
step: 406	loss: 60368.07951450348	speed (wps):1410.0200944498317
step: 538	loss: 79953.92391681671	speed (wps):1410.0946059147086
step: 670	loss: 99444.21977877617	speed (wps):1410.2850471754662
step: 802	loss: 118462.65364766121	speed (wps):1410.3534567815268
step: 934	loss: 137914.91980075836	speed (wps):1410.3501819254718
step: 1066	loss: 157278.7706208229	speed (wps):1410.3167445793622
step: 1198	loss: 175817.13746905327	speed (wps):1410.2232633517701
epoch: 34	train ppl: 65.39608624893064	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 672.3218731880188

EPOCH 35 ------------------
step: 10	loss: 1701.6708731651306	speed (wps):1390.3530941614422
step: 142	loss: 20921.216262578964	speed (wps):1409.0244020505443
step: 274	loss: 41144.278094768524	speed (wps):1409.8258331214108
step: 406	loss: 60430.605570077896	speed (wps):1410.0900552571893
step: 538	loss: 80022.74162173271	speed (wps):1410.3627296056939
step: 670	loss: 99525.15505075455	speed (wps):1410.4326162751452
step: 802	loss: 118539.04433965683	speed (wps):1410.3082348077721
step: 934	loss: 137954.170306921	speed (wps):1410.3744230555
step: 1066	loss: 157320.08803844452	speed (wps):1410.3912321380603
step: 1198	loss: 175889.4562470913	speed (wps):1410.3319070616726
epoch: 35	train ppl: 65.52981414257557	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 672.2899994850159

EPOCH 36 ------------------
step: 10	loss: 1700.2369618415833	speed (wps):1392.2803358202086
step: 142	loss: 20917.889767885208	speed (wps):1409.2767856137368
step: 274	loss: 41142.26105093956	speed (wps):1409.8598082658389
step: 406	loss: 60418.53343129158	speed (wps):1409.9587399087573
step: 538	loss: 79973.06939840317	speed (wps):1410.1635677600786
step: 670	loss: 99476.27673745155	speed (wps):1410.2584648785446
step: 802	loss: 118513.69925022125	speed (wps):1410.263949578631
step: 934	loss: 137973.5300040245	speed (wps):1410.360057975001
step: 1066	loss: 157337.73571372032	speed (wps):1410.3112139154102
step: 1198	loss: 175905.97990632057	speed (wps):1410.3131022425428
epoch: 36	train ppl: 65.51953857756098	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 672.2830982208252

EPOCH 37 ------------------
step: 10	loss: 1709.3500876426697	speed (wps):1393.2925439544651
step: 142	loss: 20922.3872089386	speed (wps):1409.2463319041854
step: 274	loss: 41126.03758215904	speed (wps):1410.0736004738665
step: 406	loss: 60420.307195186615	speed (wps):1410.4123169970223
step: 538	loss: 80011.09218120575	speed (wps):1410.2744375332254
step: 670	loss: 99500.22050976753	speed (wps):1410.4163601095363
step: 802	loss: 118507.83084154129	speed (wps):1410.475273230517
step: 934	loss: 137954.22884464264	speed (wps):1410.4552707661503
step: 1066	loss: 157297.8843343258	speed (wps):1410.231062569697
step: 1198	loss: 175869.6589899063	speed (wps):1410.008289141419
epoch: 37	train ppl: 65.51468107408662	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 672.6051149368286

EPOCH 38 ------------------
step: 10	loss: 1705.4488635063171	speed (wps):1391.713488913893
step: 142	loss: 20914.46380496025	speed (wps):1406.4675107197004
step: 274	loss: 41129.8162317276	speed (wps):1406.6444440461814
step: 406	loss: 60417.4170255661	speed (wps):1406.826026566896
step: 538	loss: 79993.74498009682	speed (wps):1407.0002175291818
step: 670	loss: 99526.1554992199	speed (wps):1406.9556383576953
step: 802	loss: 118531.76912307739	speed (wps):1407.0887461789252
step: 934	loss: 137969.97786164284	speed (wps):1407.1131877736832
step: 1066	loss: 157304.6844649315	speed (wps):1407.2104419699112
step: 1198	loss: 175877.9516363144	speed (wps):1407.3113744439
epoch: 38	train ppl: 65.52142974378877	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 673.7278516292572

EPOCH 39 ------------------
step: 10	loss: 1710.3964233398438	speed (wps):1387.4723938404159
step: 142	loss: 20904.847580194473	speed (wps):1406.071290016693
step: 274	loss: 41119.82932090759	speed (wps):1406.6637283307307
step: 406	loss: 60406.95615530014	speed (wps):1407.0653056899257
step: 538	loss: 80007.2297513485	speed (wps):1407.1839354711951
step: 670	loss: 99502.93805360794	speed (wps):1407.3009960706322
step: 802	loss: 118519.07873749733	speed (wps):1407.350471847568
step: 934	loss: 137954.90194916725	speed (wps):1407.4472309501627
step: 1066	loss: 157311.90710186958	speed (wps):1407.3570913738213
step: 1198	loss: 175891.77983164787	speed (wps):1407.3514966085816
epoch: 39	train ppl: 65.52253413731405	val ppl: 102.77089102324942	best val: 102.77086768754751	time (s) spent in epoch: 673.7341043949127

DONE

Saving learning curves to GRU_SGD_LR_SCHEDULE_model=GRU_optimizer=SGD_LR_SCHEDULE_initial_lr=10_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_save_best_0/learning_curves.npy
Set compute mode to DEFAULT for GPU 00000000:90:00.0.
All done.
