
########## Setting Up Experiment ######################

Putting log in RNN_ADAM_model=RNN_optimizer=ADAM_initial_lr=0.0001_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_save_best_0
Using the GPU
Loading data from data
  vocabulary size: 10000

########## Running Main Loop ##########################

EPOCH 0 ------------------
step: 10	loss: 3444.167046546936	speed (wps):2330.2670761884915
step: 142	loss: 36444.77687597275	speed (wps):2512.6352082257577
step: 274	loss: 67541.71366214752	speed (wps):2512.2406869171655
step: 406	loss: 97844.18792247772	speed (wps):2510.307364679116
step: 538	loss: 127920.94022750854	speed (wps):2508.5368832797417
step: 670	loss: 157715.38273334503	speed (wps):2507.1787959635244
step: 802	loss: 186951.01658821106	speed (wps):2506.756236645481
step: 934	loss: 216077.5370812416	speed (wps):2506.2172186097077
step: 1066	loss: 245026.6260266304	speed (wps):2506.109867815943
step: 1198	loss: 273709.2635965347	speed (wps):2505.7969447895603
Saving model parameters to best_params.pt
epoch: 0	train ppl: 657.7382119638382	val ppl: 398.50444954296637	best val: 398.50444954296637	time (s) spent in epoch: 379.51811599731445

EPOCH 1 ------------------
step: 10	loss: 2418.985171318054	speed (wps):2437.407981570692
step: 142	loss: 30560.88569879532	speed (wps):2498.3369875753906
step: 274	loss: 59013.54746103287	speed (wps):2501.214914774308
step: 406	loss: 87121.27729654312	speed (wps):2502.5809278992197
step: 538	loss: 115274.79673147202	speed (wps):2503.1709210561894
step: 670	loss: 143390.94767093658	speed (wps):2503.1857474475905
step: 802	loss: 171018.37632656097	speed (wps):2503.2481648326275
step: 934	loss: 198691.40368938446	speed (wps):2503.6050548123467
step: 1066	loss: 226346.28190517426	speed (wps):2502.4809023576186
step: 1198	loss: 253770.49012184143	speed (wps):2502.132071833434
Saving model parameters to best_params.pt
epoch: 1	train ppl: 417.86567646707437	val ppl: 317.3566768952514	best val: 317.3566768952514	time (s) spent in epoch: 380.24892592430115

EPOCH 2 ------------------
step: 10	loss: 2335.21187543869	speed (wps):2430.6023970710676
step: 142	loss: 29447.658734321594	speed (wps):2501.9782703531487
step: 274	loss: 56970.76298952103	speed (wps):2503.9461169023148
step: 406	loss: 84177.10073232651	speed (wps):2504.4457486565275
step: 538	loss: 111461.12092733383	speed (wps):2504.5046179850897
step: 670	loss: 138750.51883220673	speed (wps):2504.774456993953
step: 802	loss: 165611.0543680191	speed (wps):2504.4841039052385
step: 934	loss: 192563.00115823746	speed (wps):2504.201452019281
step: 1066	loss: 219511.6139101982	speed (wps):2504.0417879307265
step: 1198	loss: 246213.9473438263	speed (wps):2504.0106851314454
Saving model parameters to best_params.pt
epoch: 2	train ppl: 350.25002363946135	val ppl: 278.4563695207669	best val: 278.4563695207669	time (s) spent in epoch: 379.58727264404297

EPOCH 3 ------------------
step: 10	loss: 2284.3650007247925	speed (wps):2444.6155223779824
step: 142	loss: 28764.60987329483	speed (wps):2497.099238457283
step: 274	loss: 55694.88659143448	speed (wps):2500.3229130977325
step: 406	loss: 82316.1161661148	speed (wps):2502.019028081722
step: 538	loss: 109048.14186811447	speed (wps):2502.588440154722
step: 670	loss: 135791.99370861053	speed (wps):2502.8920112576593
step: 802	loss: 162131.41835212708	speed (wps):2502.866369031211
step: 934	loss: 188578.44877958298	speed (wps):2503.0659159524653
step: 1066	loss: 215048.8088297844	speed (wps):2503.0222646493285
step: 1198	loss: 241244.08299446106	speed (wps):2503.1895942280903
Saving model parameters to best_params.pt
epoch: 3	train ppl: 311.6343612354221	val ppl: 254.98489476618354	best val: 254.98489476618354	time (s) spent in epoch: 379.24421977996826

EPOCH 4 ------------------
step: 10	loss: 2248.758227825165	speed (wps):2448.039518959603
step: 142	loss: 28257.410197257996	speed (wps):2499.4741809064717
step: 274	loss: 54767.92041540146	speed (wps):2500.7428480924714
step: 406	loss: 80966.33632421494	speed (wps):2501.7727622953744
step: 538	loss: 107308.07101726532	speed (wps):2501.873782578026
step: 670	loss: 133678.53298664093	speed (wps):2502.5601955843426
step: 802	loss: 159611.38073444366	speed (wps):2502.684615214852
step: 934	loss: 185685.5083847046	speed (wps):2502.842226002723
step: 1066	loss: 211770.25068044662	speed (wps):2502.923393776469
step: 1198	loss: 237622.31595516205	speed (wps):2503.039468904909
Saving model parameters to best_params.pt
epoch: 4	train ppl: 286.1333898229336	val ppl: 239.75561077523815	best val: 239.75561077523815	time (s) spent in epoch: 379.47608637809753

EPOCH 5 ------------------
step: 10	loss: 2223.734223842621	speed (wps):2445.638863194833
step: 142	loss: 27875.07884979248	speed (wps):2498.9785366792403
step: 274	loss: 54055.47969341278	speed (wps):2500.1489895271093
step: 406	loss: 79908.75217199326	speed (wps):2501.1692225251077
step: 538	loss: 105903.91768455505	speed (wps):2501.3489554769053
step: 670	loss: 131948.12412261963	speed (wps):2501.750973086046
step: 802	loss: 157569.15058135986	speed (wps):2501.8820009937435
step: 934	loss: 183316.39396429062	speed (wps):2502.1241571187375
step: 1066	loss: 209090.53192138672	speed (wps):2502.363982592377
step: 1198	loss: 234617.85898923874	speed (wps):2502.307685430173
Saving model parameters to best_params.pt
epoch: 5	train ppl: 266.42392297931	val ppl: 227.75281970257697	best val: 227.75281970257697	time (s) spent in epoch: 379.39206552505493

EPOCH 6 ------------------
step: 10	loss: 2199.86310005188	speed (wps):2447.926703196927
step: 142	loss: 27578.190495967865	speed (wps):2497.536000834523
step: 274	loss: 53481.495027542114	speed (wps):2499.733990329335
step: 406	loss: 79045.5298781395	speed (wps):2500.453847787722
step: 538	loss: 104768.69457244873	speed (wps):2500.5452283994687
step: 670	loss: 130512.73087263107	speed (wps):2500.696384679866
step: 802	loss: 155872.9627776146	speed (wps):2500.9716844633776
step: 934	loss: 181369.1799044609	speed (wps):2501.138749068629
step: 1066	loss: 206892.0374774933	speed (wps):2501.187896915166
step: 1198	loss: 232155.22557258606	speed (wps):2501.108649005303
Saving model parameters to best_params.pt
epoch: 6	train ppl: 251.2818692311389	val ppl: 218.27351874900276	best val: 218.27351874900276	time (s) spent in epoch: 379.54702281951904

EPOCH 7 ------------------
step: 10	loss: 2182.2207736968994	speed (wps):2451.704255733441
step: 142	loss: 27286.148397922516	speed (wps):2498.6306944796997
step: 274	loss: 52946.56599521637	speed (wps):2500.9952052779354
step: 406	loss: 78266.3793349266	speed (wps):2501.4105940604463
step: 538	loss: 103711.55684232712	speed (wps):2502.1174870479194
step: 670	loss: 129207.53406047821	speed (wps):2502.179445981019
step: 802	loss: 154336.5518951416	speed (wps):2502.1500864397744
step: 934	loss: 179609.9296426773	speed (wps):2502.1108841266005
step: 1066	loss: 204912.78071165085	speed (wps):2502.1710951588025
step: 1198	loss: 229935.8963227272	speed (wps):2502.106115525032
Saving model parameters to best_params.pt
epoch: 7	train ppl: 238.6002666803504	val ppl: 208.47825717614202	best val: 208.47825717614202	time (s) spent in epoch: 379.4616301059723

EPOCH 8 ------------------
step: 10	loss: 2155.653259754181	speed (wps):2449.407123347846
step: 142	loss: 27031.0680603981	speed (wps):2500.0584174895953
step: 274	loss: 52472.2243475914	speed (wps):2500.4916492072525
step: 406	loss: 77574.22390699387	speed (wps):2500.824113000061
step: 538	loss: 102809.03792142868	speed (wps):2501.2392534896835
step: 670	loss: 128094.0807557106	speed (wps):2501.2542379554448
step: 802	loss: 152965.30443906784	speed (wps):2501.321746579947
step: 934	loss: 178037.9588007927	speed (wps):2501.5803329235373
step: 1066	loss: 203124.00467395782	speed (wps):2501.424613488587
step: 1198	loss: 227944.64223623276	speed (wps):2501.41609041876
Saving model parameters to best_params.pt
epoch: 8	train ppl: 227.57630830465413	val ppl: 201.4555521660703	best val: 201.4555521660703	time (s) spent in epoch: 379.6362543106079

EPOCH 9 ------------------
step: 10	loss: 2141.1461520195007	speed (wps):2448.985873577646
step: 142	loss: 26801.628262996674	speed (wps):2496.971668444611
step: 274	loss: 52048.73715162277	speed (wps):2499.4992974313927
step: 406	loss: 76928.28205347061	speed (wps):2499.784052971798
step: 538	loss: 101986.4610671997	speed (wps):2500.5413602367166
step: 670	loss: 127089.1511130333	speed (wps):2500.883631982112
step: 802	loss: 151788.03750753403	speed (wps):2501.1443483711714
step: 934	loss: 176673.05137634277	speed (wps):2501.1713818955827
step: 1066	loss: 201577.5536417961	speed (wps):2501.363454369027
step: 1198	loss: 226195.38402557373	speed (wps):2501.521217922567
Saving model parameters to best_params.pt
epoch: 9	train ppl: 218.35460907371305	val ppl: 196.41471913422745	best val: 196.41471913422745	time (s) spent in epoch: 379.67772006988525

EPOCH 10 ------------------
step: 10	loss: 2130.6548404693604	speed (wps):2433.450424164172
step: 142	loss: 26601.80868625641	speed (wps):2498.680019151496
step: 274	loss: 51682.89912223816	speed (wps):2500.659532913462
step: 406	loss: 76391.31916284561	speed (wps):2501.278334218755
step: 538	loss: 101232.06686496735	speed (wps):2501.1028905882304
step: 670	loss: 126156.40516519547	speed (wps):2501.614518664049
step: 802	loss: 150657.09408283234	speed (wps):2501.787567158524
step: 934	loss: 175401.0989165306	speed (wps):2501.8650171512245
step: 1066	loss: 200153.56155395508	speed (wps):2502.173817165702
step: 1198	loss: 224592.33206510544	speed (wps):2502.1331068957466
Saving model parameters to best_params.pt
epoch: 10	train ppl: 210.1843068828422	val ppl: 191.42150652046053	best val: 191.42150652046053	time (s) spent in epoch: 379.9452295303345

EPOCH 11 ------------------
step: 10	loss: 2115.5066633224487	speed (wps):2439.3625720207783
step: 142	loss: 26409.21983242035	speed (wps):2498.6617879787045
step: 274	loss: 51323.9608335495	speed (wps):2500.52244710825
step: 406	loss: 75845.39602041245	speed (wps):2501.535169860844
step: 538	loss: 100551.88212156296	speed (wps):2501.879537614425
step: 670	loss: 125307.0255446434	speed (wps):2501.806996329905
step: 802	loss: 149670.09614229202	speed (wps):2501.8468416766277
step: 934	loss: 174277.21638441086	speed (wps):2501.9171920039335
step: 1066	loss: 198857.13977575302	speed (wps):2501.6946133846873
step: 1198	loss: 223124.22751903534	speed (wps):2501.6982747221564
Saving model parameters to best_params.pt
epoch: 11	train ppl: 203.13402076642186	val ppl: 187.71079852843215	best val: 187.71079852843215	time (s) spent in epoch: 380.10883688926697

EPOCH 12 ------------------
step: 10	loss: 2101.0995078086853	speed (wps):2448.000737368323
step: 142	loss: 26247.270414829254	speed (wps):2495.5098807817444
step: 274	loss: 51014.864807128906	speed (wps):2497.0012920394497
step: 406	loss: 75393.13106298447	speed (wps):2499.175158171035
step: 538	loss: 99924.0303182602	speed (wps):2500.359894031417
step: 670	loss: 124528.2350897789	speed (wps):2500.0930128475516
step: 802	loss: 148701.44091129303	speed (wps):2500.5006540255026
step: 934	loss: 173139.25060272217	speed (wps):2503.1170932812333
step: 1066	loss: 197563.1023478508	speed (wps):2508.0224458540865
step: 1198	loss: 221705.06509780884	speed (wps):2512.839248547942
Saving model parameters to best_params.pt
epoch: 12	train ppl: 196.46271930559817	val ppl: 184.9639343661528	best val: 184.9639343661528	time (s) spent in epoch: 377.04896092414856

EPOCH 13 ------------------
step: 10	loss: 2101.1217379570007	speed (wps):2508.5201465616856
step: 142	loss: 26102.679121494293	speed (wps):2559.0704082320854
step: 274	loss: 50749.985263347626	speed (wps):2560.8953455000683
step: 406	loss: 74980.08462667465	speed (wps):2561.667349730964
step: 538	loss: 99368.2813000679	speed (wps):2562.1421800018493
step: 670	loss: 123807.49858379364	speed (wps):2562.126921991116
step: 802	loss: 147858.21229934692	speed (wps):2562.7467311729165
step: 934	loss: 172161.61853075027	speed (wps):2562.836748606463
step: 1066	loss: 196458.63132476807	speed (wps):2562.957724448986
step: 1198	loss: 220423.0864238739	speed (wps):2563.1419576429553
Saving model parameters to best_params.pt
epoch: 13	train ppl: 190.43084552695066	val ppl: 180.92039689233297	best val: 180.92039689233297	time (s) spent in epoch: 370.83910298347473

EPOCH 14 ------------------
step: 10	loss: 2079.0112352371216	speed (wps):2510.584841049718
step: 142	loss: 25954.306015968323	speed (wps):2561.546122409106
step: 274	loss: 50476.699035167694	speed (wps):2562.812201117972
step: 406	loss: 74574.54962730408	speed (wps):2563.34111778906
step: 538	loss: 98848.39728832245	speed (wps):2563.6325989256643
step: 670	loss: 123179.6849822998	speed (wps):2563.3783513262865
step: 802	loss: 147106.31595134735	speed (wps):2563.734667293788
step: 934	loss: 171279.78704929352	speed (wps):2563.7966819322432
step: 1066	loss: 195443.71420383453	speed (wps):2563.6551351663843
step: 1198	loss: 219301.80672168732	speed (wps):2563.787005804806
Saving model parameters to best_params.pt
epoch: 14	train ppl: 185.48172210568706	val ppl: 180.1754106946375	best val: 180.1754106946375	time (s) spent in epoch: 370.33261013031006

EPOCH 15 ------------------
step: 10	loss: 2071.331570148468	speed (wps):2510.153603227557
step: 142	loss: 25802.097992897034	speed (wps):2561.000281426504
step: 274	loss: 50199.14521932602	speed (wps):2562.2294154808724
step: 406	loss: 74165.68394422531	speed (wps):2562.9584925076024
step: 538	loss: 98307.73284435272	speed (wps):2563.4369480964338
step: 670	loss: 122517.65192270279	speed (wps):2563.519969260838
step: 802	loss: 146324.39857244492	speed (wps):2563.8404574210867
step: 934	loss: 170397.86566257477	speed (wps):2563.9109815549723
step: 1066	loss: 194426.0750079155	speed (wps):2563.8194682799167
step: 1198	loss: 218136.42021894455	speed (wps):2563.915573364958
Saving model parameters to best_params.pt
epoch: 15	train ppl: 180.5145237651425	val ppl: 174.24123299721165	best val: 174.24123299721165	time (s) spent in epoch: 370.3189609050751

EPOCH 16 ------------------
step: 10	loss: 2067.052550315857	speed (wps):2511.9829917652337
step: 142	loss: 25681.498103141785	speed (wps):2562.010084175841
step: 274	loss: 49974.75904226303	speed (wps):2562.709203357386
step: 406	loss: 73815.40653467178	speed (wps):2563.1260539718483
step: 538	loss: 97845.95430135727	speed (wps):2563.5377680388888
step: 670	loss: 121913.1753706932	speed (wps):2563.423333012933
step: 802	loss: 145604.3932080269	speed (wps):2563.6423809369126
step: 934	loss: 169567.47522830963	speed (wps):2563.8126048242398
step: 1066	loss: 193498.63014936447	speed (wps):2563.769967858942
step: 1198	loss: 217114.52611923218	speed (wps):2563.8331503151776
epoch: 16	train ppl: 176.13710160984718	val ppl: 175.05745268799149	best val: 174.24123299721165	time (s) spent in epoch: 369.54714941978455

EPOCH 17 ------------------
step: 10	loss: 2047.856433391571	speed (wps):2511.7249197240785
step: 142	loss: 25543.743331432343	speed (wps):2561.5296659665128
step: 274	loss: 49752.8075504303	speed (wps):2562.5881496804705
step: 406	loss: 73458.77500772476	speed (wps):2562.7453121114895
step: 538	loss: 97359.81078147888	speed (wps):2563.3713876220986
step: 670	loss: 121331.98611736298	speed (wps):2563.2324802337407
step: 802	loss: 144868.28051567078	speed (wps):2563.4813501316667
step: 934	loss: 168737.64179944992	speed (wps):2563.588835698671
step: 1066	loss: 192563.5182094574	speed (wps):2563.5500737227167
step: 1198	loss: 216046.64398431778	speed (wps):2563.658985098789
Saving model parameters to best_params.pt
epoch: 17	train ppl: 171.81443511202986	val ppl: 172.3873068822357	best val: 172.3873068822357	time (s) spent in epoch: 370.71972465515137

EPOCH 18 ------------------
step: 10	loss: 2044.3759298324585	speed (wps):2507.097042537324
step: 142	loss: 25422.248561382294	speed (wps):2559.9132303387078
step: 274	loss: 49518.87899875641	speed (wps):2561.7611214238414
step: 406	loss: 73143.0863904953	speed (wps):2562.5221494011457
step: 538	loss: 96934.60787534714	speed (wps):2563.038251554348
step: 670	loss: 120794.58101034164	speed (wps):2563.0671317128817
step: 802	loss: 144241.30900621414	speed (wps):2563.3377275780153
step: 934	loss: 167999.43974018097	speed (wps):2563.472118331455
step: 1066	loss: 191743.19594621658	speed (wps):2563.375090431834
step: 1198	loss: 215123.84180545807	speed (wps):2563.5460909565077
Saving model parameters to best_params.pt
epoch: 18	train ppl: 168.05110852431955	val ppl: 171.15157687598483	best val: 171.15157687598483	time (s) spent in epoch: 370.44075179100037

EPOCH 19 ------------------
step: 10	loss: 2039.3343091011047	speed (wps):2511.851507104334
step: 142	loss: 25334.53557252884	speed (wps):2561.0198710517893
step: 274	loss: 49332.26114273071	speed (wps):2562.613493305397
step: 406	loss: 72837.61845111847	speed (wps):2563.0571521125466
step: 538	loss: 96532.08968400955	speed (wps):2563.7442662537896
step: 670	loss: 120291.22756719589	speed (wps):2563.613446937505
step: 802	loss: 143619.58124160767	speed (wps):2563.744020634856
step: 934	loss: 167281.7942595482	speed (wps):2563.8276635126413
step: 1066	loss: 190913.2021999359	speed (wps):2563.888422077472
step: 1198	loss: 214185.5204963684	speed (wps):2564.121861488107
Saving model parameters to best_params.pt
epoch: 19	train ppl: 164.29446641035113	val ppl: 168.40381303494783	best val: 168.40381303494783	time (s) spent in epoch: 371.4413352012634

EPOCH 20 ------------------
step: 10	loss: 2027.5324201583862	speed (wps):2494.461001509059
step: 142	loss: 25212.923192977905	speed (wps):2559.6056738857064
step: 274	loss: 49108.97168636322	speed (wps):2562.0538867711157
step: 406	loss: 72520.15944957733	speed (wps):2562.567897694526
step: 538	loss: 96103.79894018173	speed (wps):2563.2791211604813
step: 670	loss: 119793.24627637863	speed (wps):2563.26673778731
step: 802	loss: 143008.43928337097	speed (wps):2563.603515827958
step: 934	loss: 166603.9651942253	speed (wps):2563.6713194121658
step: 1066	loss: 190163.5325050354	speed (wps):2563.680331892662
step: 1198	loss: 213342.35154867172	speed (wps):2563.7829820329443
epoch: 20	train ppl: 161.04605732861427	val ppl: 169.5511107118904	best val: 168.40381303494783	time (s) spent in epoch: 369.54470562934875

EPOCH 21 ------------------
step: 10	loss: 2017.6257181167603	speed (wps):2510.5424912283756
step: 142	loss: 25081.74263715744	speed (wps):2560.8629750013133
step: 274	loss: 48915.27392864227	speed (wps):2562.0362693714715
step: 406	loss: 72241.13904476166	speed (wps):2562.715006701225
step: 538	loss: 95763.9708352089	speed (wps):2563.2220880148716
step: 670	loss: 119341.69298410416	speed (wps):2563.286104782579
step: 802	loss: 142504.4019794464	speed (wps):2563.5022998001614
step: 934	loss: 165982.97197580338	speed (wps):2563.8044781385597
step: 1066	loss: 189447.96611070633	speed (wps):2563.6632354087983
step: 1198	loss: 212550.79761743546	speed (wps):2563.8274664198066
Saving model parameters to best_params.pt
epoch: 21	train ppl: 158.06922167714782	val ppl: 165.0260879384635	best val: 165.0260879384635	time (s) spent in epoch: 370.6880931854248

EPOCH 22 ------------------
step: 10	loss: 2013.2303738594055	speed (wps):2506.755333099497
step: 142	loss: 25027.08088874817	speed (wps):2560.3239358399696
step: 274	loss: 48732.64998912811	speed (wps):2562.5491917480867
step: 406	loss: 71943.13794851303	speed (wps):2562.886895249419
step: 538	loss: 95376.82250499725	speed (wps):2563.638355035421
step: 670	loss: 118867.85106420517	speed (wps):2563.6662834210997
step: 802	loss: 141949.36896562576	speed (wps):2564.0649052587264
step: 934	loss: 165357.88977861404	speed (wps):2564.2282407069515
step: 1066	loss: 188752.23261356354	speed (wps):2564.1678171270496
step: 1198	loss: 211758.6067223549	speed (wps):2564.257513817383
epoch: 22	train ppl: 155.10171542437126	val ppl: 165.95073710941628	best val: 165.0260879384635	time (s) spent in epoch: 369.48680806159973

EPOCH 23 ------------------
step: 10	loss: 2004.395592212677	speed (wps):2510.654321270776
step: 142	loss: 24936.60109758377	speed (wps):2561.3175640051313
step: 274	loss: 48561.727685928345	speed (wps):2561.9934666849454
step: 406	loss: 71687.62158632278	speed (wps):2563.019670792936
step: 538	loss: 95014.18146133423	speed (wps):2563.4876207637944
step: 670	loss: 118405.06009817123	speed (wps):2563.5583409188644
step: 802	loss: 141406.77613973618	speed (wps):2563.798937693318
step: 934	loss: 164710.18528461456	speed (wps):2563.6648024957476
step: 1066	loss: 188002.8577852249	speed (wps):2563.865113927638
step: 1198	loss: 210898.28022241592	speed (wps):2563.9928175732553
epoch: 23	train ppl: 151.95237986229589	val ppl: 165.53842877024988	best val: 165.0260879384635	time (s) spent in epoch: 369.5146379470825

EPOCH 24 ------------------
step: 10	loss: 1998.5388660430908	speed (wps):2507.7881406582233
step: 142	loss: 24832.6149392128	speed (wps):2560.9556513180464
step: 274	loss: 48367.43119955063	speed (wps):2562.4493623700723
step: 406	loss: 71411.9039273262	speed (wps):2563.038394823491
step: 538	loss: 94676.25630378723	speed (wps):2563.4494219491335
step: 670	loss: 118008.34295749664	speed (wps):2563.355053928073
step: 802	loss: 140927.4096775055	speed (wps):2563.7613140410194
step: 934	loss: 164177.27046728134	speed (wps):2563.907518941329
step: 1066	loss: 187399.46819067	speed (wps):2563.881331805913
step: 1198	loss: 210222.49798297882	speed (wps):2564.114413240885
Saving model parameters to best_params.pt
epoch: 24	train ppl: 149.59039253241178	val ppl: 162.13388413817563	best val: 162.13388413817563	time (s) spent in epoch: 370.1291744709015

EPOCH 25 ------------------
step: 10	loss: 1986.7907333374023	speed (wps):2516.135050794216
step: 142	loss: 24711.519243717194	speed (wps):2560.7093623402343
step: 274	loss: 48203.425793647766	speed (wps):2562.8902561908403
step: 406	loss: 71163.18875551224	speed (wps):2563.2588982841876
step: 538	loss: 94342.63902187347	speed (wps):2564.049231946732
step: 670	loss: 117597.10627555847	speed (wps):2563.8775677197264
step: 802	loss: 140423.69516134262	speed (wps):2563.8976844715385
step: 934	loss: 163576.40532970428	speed (wps):2563.9990418847083
step: 1066	loss: 186729.2663025856	speed (wps):2563.8828845699322
step: 1198	loss: 209477.82933712006	speed (wps):2564.020146599679
epoch: 25	train ppl: 147.02765049811202	val ppl: 163.19344338722252	best val: 162.13388413817563	time (s) spent in epoch: 369.50885796546936

EPOCH 26 ------------------
step: 10	loss: 1989.2074275016785	speed (wps):2506.7681747080023
step: 142	loss: 24656.709978580475	speed (wps):2560.2488066467245
step: 274	loss: 48050.247588157654	speed (wps):2562.65595882756
step: 406	loss: 70947.6070523262	speed (wps):2562.8273172868335
step: 538	loss: 94076.27014160156	speed (wps):2563.371678274854
step: 670	loss: 117260.42767524719	speed (wps):2563.5174574467287
step: 802	loss: 140017.82408952713	speed (wps):2563.3126949192783
step: 934	loss: 163104.7724056244	speed (wps):2563.523832609687
step: 1066	loss: 186157.99681901932	speed (wps):2563.644832134804
step: 1198	loss: 208830.08445501328	speed (wps):2563.6429477036404
Saving model parameters to best_params.pt
epoch: 26	train ppl: 144.6188079197584	val ppl: 159.4811677091527	best val: 159.4811677091527	time (s) spent in epoch: 370.1987273693085

EPOCH 27 ------------------
step: 10	loss: 1978.10777425766	speed (wps):2509.8873244559227
step: 142	loss: 24562.69676208496	speed (wps):2558.8857873581082
step: 274	loss: 47902.19700336456	speed (wps):2562.2655584043737
step: 406	loss: 70694.73701238632	speed (wps):2562.958860810942
step: 538	loss: 93712.52974033356	speed (wps):2563.197065974769
step: 670	loss: 116814.35322999954	speed (wps):2563.562977752689
step: 802	loss: 139487.8884959221	speed (wps):2563.451350557345
step: 934	loss: 162520.46033382416	speed (wps):2563.520150803909
step: 1066	loss: 185512.5094985962	speed (wps):2563.7145968783598
step: 1198	loss: 208104.26181793213	speed (wps):2563.6017853521903
epoch: 27	train ppl: 142.13821026150137	val ppl: 161.0116832423412	best val: 159.4811677091527	time (s) spent in epoch: 369.55211639404297

EPOCH 28 ------------------
step: 10	loss: 1969.1703701019287	speed (wps):2511.065035725529
step: 142	loss: 24503.559727668762	speed (wps):2560.328682304495
step: 274	loss: 47780.62900066376	speed (wps):2561.7797429327106
step: 406	loss: 70500.85290193558	speed (wps):2563.1205671963803
step: 538	loss: 93482.42043495178	speed (wps):2563.4515770644784
step: 670	loss: 116496.63469314575	speed (wps):2563.7397837326835
step: 802	loss: 139089.8696398735	speed (wps):2564.0976827550344
step: 934	loss: 162035.09301662445	speed (wps):2563.93281347754
step: 1066	loss: 184954.55932855606	speed (wps):2564.032506401523
step: 1198	loss: 207480.42384147644	speed (wps):2564.025241209961
epoch: 28	train ppl: 140.03803872968854	val ppl: 159.73421215073952	best val: 159.4811677091527	time (s) spent in epoch: 369.50811767578125

EPOCH 29 ------------------
step: 10	loss: 1964.9865627288818	speed (wps):2508.8093267392187
step: 142	loss: 24387.9248547554	speed (wps):2561.034524412403
step: 274	loss: 47584.20437812805	speed (wps):2562.280869651092
step: 406	loss: 70255.41782855988	speed (wps):2563.3335955821185
step: 538	loss: 93146.16709470749	speed (wps):2563.701487052453
step: 670	loss: 116111.65033102036	speed (wps):2563.502530100551
step: 802	loss: 138632.0417380333	speed (wps):2563.771420323031
step: 934	loss: 161505.4923439026	speed (wps):2563.656698294328
step: 1066	loss: 184363.15682411194	speed (wps):2563.7139213046426
step: 1198	loss: 206812.8588795662	speed (wps):2563.886846071026
epoch: 29	train ppl: 137.89178764833446	val ppl: 163.17840396535647	best val: 159.4811677091527	time (s) spent in epoch: 369.5423846244812

EPOCH 30 ------------------
step: 10	loss: 1959.6194505691528	speed (wps):2505.7408727956445
step: 142	loss: 24344.735548496246	speed (wps):2560.2224843689464
step: 274	loss: 47462.75181531906	speed (wps):2561.8637097113547
step: 406	loss: 70051.44598722458	speed (wps):2562.408887501903
step: 538	loss: 92899.71594333649	speed (wps):2563.2680938070876
step: 670	loss: 115808.82382392883	speed (wps):2563.339051178915
step: 802	loss: 138289.42722082138	speed (wps):2563.3885831165276
step: 934	loss: 161096.61194086075	speed (wps):2563.607394250995
step: 1066	loss: 183887.77893781662	speed (wps):2563.536736066786
step: 1198	loss: 206271.24967098236	speed (wps):2563.7271378648065
Saving model parameters to best_params.pt
epoch: 30	train ppl: 136.1671647134351	val ppl: 159.4773770149091	best val: 159.4773770149091	time (s) spent in epoch: 370.4435451030731

EPOCH 31 ------------------
step: 10	loss: 1950.4100942611694	speed (wps):2503.4671582213646
step: 142	loss: 24272.67061471939	speed (wps):2557.8171101724924
step: 274	loss: 47350.2117562294	speed (wps):2561.472039140391
step: 406	loss: 69847.24323272705	speed (wps):2562.229756105009
step: 538	loss: 92597.57181167603	speed (wps):2562.5667274015896
step: 670	loss: 115398.82313489914	speed (wps):2563.205873898772
step: 802	loss: 137789.79772806168	speed (wps):2563.1921063375444
step: 934	loss: 160541.86374664307	speed (wps):2563.3665489717187
step: 1066	loss: 183229.3777704239	speed (wps):2563.637879575888
step: 1198	loss: 205502.60923147202	speed (wps):2563.576929517903
Saving model parameters to best_params.pt
epoch: 31	train ppl: 133.68131885726072	val ppl: 156.99706870778172	best val: 156.99706870778172	time (s) spent in epoch: 370.34004831314087

EPOCH 32 ------------------
step: 10	loss: 1952.0284390449524	speed (wps):2511.454206208652
step: 142	loss: 24172.8072142601	speed (wps):2560.8412635018403
step: 274	loss: 47157.96556711197	speed (wps):2562.043756939962
step: 406	loss: 69620.5433011055	speed (wps):2562.905249052008
step: 538	loss: 92289.81626987457	speed (wps):2562.9209343122625
step: 670	loss: 115043.22944879532	speed (wps):2563.162954088918
step: 802	loss: 137375.14531373978	speed (wps):2563.434735839261
step: 934	loss: 160067.27185964584	speed (wps):2563.583767575196
step: 1066	loss: 182680.65603256226	speed (wps):2563.92461056146
step: 1198	loss: 204902.22666502	speed (wps):2563.840062892066
epoch: 32	train ppl: 131.89620292111104	val ppl: 160.09145658813478	best val: 156.99706870778172	time (s) spent in epoch: 369.51338815689087

EPOCH 33 ------------------
step: 10	loss: 1936.4500784873962	speed (wps):2507.2591730459326
step: 142	loss: 24108.847522735596	speed (wps):2559.7236031468037
step: 274	loss: 47062.217597961426	speed (wps):2561.39803578871
step: 406	loss: 69457.43340969086	speed (wps):2562.404859888271
step: 538	loss: 92065.20937681198	speed (wps):2562.619008968164
step: 670	loss: 114722.92669057846	speed (wps):2562.978962115262
step: 802	loss: 137006.36636257172	speed (wps):2563.255616600356
step: 934	loss: 159627.5205731392	speed (wps):2563.1875296482463
step: 1066	loss: 182231.94537878036	speed (wps):2563.416290187672
step: 1198	loss: 204382.8662467003	speed (wps):2563.468763525685
epoch: 33	train ppl: 130.2190024237506	val ppl: 157.37854924896595	best val: 156.99706870778172	time (s) spent in epoch: 369.54739356040955

EPOCH 34 ------------------
step: 10	loss: 1936.1811137199402	speed (wps):2510.755620955296
step: 142	loss: 24053.131778240204	speed (wps):2563.35389811311
step: 274	loss: 46915.5984044075	speed (wps):2565.562376304264
step: 406	loss: 69256.96742296219	speed (wps):2566.7461222251545
step: 538	loss: 91803.94376754761	speed (wps):2567.405946103666
step: 670	loss: 114424.23836231232	speed (wps):2567.7705812609856
step: 802	loss: 136622.30336666107	speed (wps):2568.0062169231865
step: 934	loss: 159181.6222000122	speed (wps):2568.103914979872
step: 1066	loss: 181715.86482524872	speed (wps):2568.2611636377856
step: 1198	loss: 203813.78980398178	speed (wps):2568.321481978531
epoch: 34	train ppl: 128.44161050166153	val ppl: 158.51677822490427	best val: 156.99706870778172	time (s) spent in epoch: 368.8778100013733

EPOCH 35 ------------------
step: 10	loss: 1934.5018196105957	speed (wps):2512.2299778765105
step: 142	loss: 24011.403937339783	speed (wps):2564.773197017624
step: 274	loss: 46832.38738775253	speed (wps):2566.7405178337954
step: 406	loss: 69082.31506109238	speed (wps):2567.393378667647
step: 538	loss: 91575.80415010452	speed (wps):2567.828310713329
step: 670	loss: 114147.83365488052	speed (wps):2568.115386527169
step: 802	loss: 136273.57073545456	speed (wps):2568.1428351104564
step: 934	loss: 158777.1367073059	speed (wps):2568.314425910262
step: 1066	loss: 181262.56788492203	speed (wps):2568.4753385929225
step: 1198	loss: 203345.26970148087	speed (wps):2568.534726097155
epoch: 35	train ppl: 126.91567446967761	val ppl: 157.88018671152423	best val: 156.99706870778172	time (s) spent in epoch: 368.8371014595032

EPOCH 36 ------------------
step: 10	loss: 1922.4337363243103	speed (wps):2515.6580100294054
step: 142	loss: 23891.736512184143	speed (wps):2565.034372054864
step: 274	loss: 46630.36320447922	speed (wps):2566.81052166461
step: 406	loss: 68813.84785175323	speed (wps):2567.694449852613
step: 538	loss: 91238.28162193298	speed (wps):2567.931976562201
step: 670	loss: 113751.96594953537	speed (wps):2568.165666857365
step: 802	loss: 135852.81484365463	speed (wps):2568.3367001693982
step: 934	loss: 158305.47931671143	speed (wps):2568.564382773023
step: 1066	loss: 180725.85526704788	speed (wps):2568.57067418113
step: 1198	loss: 202732.28656291962	speed (wps):2568.695710500506
epoch: 36	train ppl: 125.19689605492579	val ppl: 157.3812601453149	best val: 156.99706870778172	time (s) spent in epoch: 368.8160810470581

EPOCH 37 ------------------
step: 10	loss: 1915.9819197654724	speed (wps):2512.243266480749
step: 142	loss: 23830.762803554535	speed (wps):2564.8631481694642
step: 274	loss: 46527.05421447754	speed (wps):2567.007252952946
step: 406	loss: 68656.99197530746	speed (wps):2567.8642921210067
step: 538	loss: 91045.04004955292	speed (wps):2568.2034374814907
step: 670	loss: 113501.20233297348	speed (wps):2568.415132474405
step: 802	loss: 135529.97197389603	speed (wps):2568.5812953011
step: 934	loss: 157905.23077011108	speed (wps):2568.6960769669527
step: 1066	loss: 180266.4120745659	speed (wps):2568.741567298726
step: 1198	loss: 202179.90412712097	speed (wps):2568.7621987823336
epoch: 37	train ppl: 123.50925092073946	val ppl: 163.02903065767904	best val: 156.99706870778172	time (s) spent in epoch: 368.8217167854309

EPOCH 38 ------------------
step: 10	loss: 1909.9454832077026	speed (wps):2514.7553812267975
step: 142	loss: 23776.165359020233	speed (wps):2565.3053495769623
step: 274	loss: 46411.82143688202	speed (wps):2567.094909157905
step: 406	loss: 68487.89781808853	speed (wps):2567.951492543199
step: 538	loss: 90801.08017683029	speed (wps):2568.352096643199
step: 670	loss: 113195.60513496399	speed (wps):2568.3591468170825
step: 802	loss: 135168.48467826843	speed (wps):2568.5094506350156
step: 934	loss: 157472.7870941162	speed (wps):2568.7235668351914
step: 1066	loss: 179776.33892536163	speed (wps):2568.6802630431353
step: 1198	loss: 201650.18087148666	speed (wps):2568.7985877288165
Saving model parameters to best_params.pt
epoch: 38	train ppl: 122.0380134083588	val ppl: 156.34080967885654	best val: 156.34080967885654	time (s) spent in epoch: 370.09926199913025

EPOCH 39 ------------------
step: 10	loss: 1912.1243381500244	speed (wps):2514.5490115746143
step: 142	loss: 23740.058875083923	speed (wps):2565.7933318240257
step: 274	loss: 46355.38302898407	speed (wps):2567.744690277594
step: 406	loss: 68368.98600101471	speed (wps):2568.388406041206
step: 538	loss: 90623.76435279846	speed (wps):2568.549478212952
step: 670	loss: 112973.74543428421	speed (wps):2568.650365873082
step: 802	loss: 134892.4731373787	speed (wps):2568.744254929417
step: 934	loss: 157158.39823961258	speed (wps):2568.8339288230104
step: 1066	loss: 179406.8177342415	speed (wps):2568.885519322408
step: 1198	loss: 201236.0736131668	speed (wps):2568.884492825486
epoch: 39	train ppl: 120.76277003196358	val ppl: 158.46799992201798	best val: 156.34080967885654	time (s) spent in epoch: 368.79359436035156

DONE

Saving learning curves to RNN_ADAM_model=RNN_optimizer=ADAM_initial_lr=0.0001_batch_size=20_seq_len=35_hidden_size=1500_num_layers=2_dp_keep_prob=0.35_save_best_0/learning_curves.npy
Set compute mode to DEFAULT for GPU 00000000:8F:00.0.
All done.
